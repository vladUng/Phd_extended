# Load the libraries

This is an adapted version of the work from [Marzouka & Pontus](https://github.com/NourMarzouka/multiclassPairs)

```{r}
library(multiclassPairs)
library(leukemiasEset, quietly = TRUE) 

data(leukemiasEset) 
knitr::kable(table(pData(leukemiasEset)[,"LeukemiaType"]))

path <- '~/Developer/York/R/98TFs/98TFs_subtypes_aggFiltering_gc42.tsv'

# Step 1: Read the CSV file
tpms_df <- read.csv(file = path, header = TRUE, sep = '\t')

# Step 2: Set the 'Sample' column as row names
samples <- tpms_df$Sample

# Step 3: Remove the 'Sample' column
tpms_df <- tpms_df[, !colnames(tpms_df) %in% "Sample"]
rownames(tpms_df) <- samples

dendrogram_cut <- tpms_df$dendrogram_cut
dendrogram_label <- tpms_df$dendrogram_label

# Step 4: Separate gene expression data and subtype labels
gene_data <- tpms_df[, !colnames(tpms_df) %in% c("dendrogram_cut", "dendrogram_label")]

# Verify that row names of gene_data match tpms_df
head(rownames(gene_data))  # Should match the sample names

# Transpose the gene_data to make samples columns and genes rows
gene_data <- t(gene_data)

```

# Prep

## Filter the datasets

```{r}

classifier_label <-'dendrogram_label'
unique_classes <- unique(tpms_df[[classifier_label]])

# Step 2: Extract class labels
# Use 'dendrogram_cut' as the class labels
class_labels <- as.factor(tpms_df[[classifier_label]])

# Check dimensions to confirm alignment
if (ncol(gene_data) != length(class_labels)) {
  stop("Number of samples in 'gene_data' and 'class_labels' do not match after transposing.")
}

# Step 3: Create the data object without platform labels
data_object <- ReadData(Data = gene_data,
                        Labels = class_labels,
                        verbose = FALSE)

# View the created object
print(data_object)


```

```{r}

# Use your dataset
usedDataset <- gene_data

# Get the number of samples (columns)
n <- ncol(usedDataset)

# Set seed for reproducibility
set.seed(1234)

# Step 1: Split samples into training (60%) and testing (40%)
training_samples <- sample(1:n, size = floor(n * 0.7))

# Create training and testing sets with first 1000 genes (rows)
train <- usedDataset[, training_samples]
test_2 <- usedDataset[, -training_samples]

test_labels <- class_labels[-training_samples]
train_labels <- class_labels[training_samples]

# Step 2: Ensure no shared samples between training and testing sets
# Here, columns represent samples, so we check the column names
shared_samples <- sum(colnames(test) %in% colnames(train)) == 0

train_object <- ReadData(Data = train,
                         Labels = train_labels,
                         verbose = TRUE)

# Print the check result
if (shared_samples) {
  cat("No shared samples between training and testing datasets. Splits are clean.\n")
} else {
  cat("Warning: Shared samples exist between training and testing datasets.\n")
}

```

## Gene filtering

Using option 2 with Dunn's test on ranked that as it was recommended to give more weight to small subgroups

```{r message=TRUE, warning=TRUE}

# let's go with gene filtering using one_vs_one option
# for featureNo argument, a sufficient number of returned features is 
# recommended if large number of rules is used in the downstream training steps.
filtered_genes <- filter_genes_TSP(data_object = train_object,
                                   filter = "one_vs_one",
                                   platform_wise = FALSE,
                                   featureNo = 5000,
                                   UpDown = TRUE,
                                   verbose = TRUE)
filtered_genes

```

# Model training

```{r}

# Let's train our model
classifier <- train_one_vs_rest_TSP(data_object = train_object,
                                    filtered_genes = filtered_genes,
                                    k_range = 5:50,
                                    include_pivot = FALSE,
                                    one_vs_one_scores = TRUE,
                                    platform_wise_scores = FALSE,
                                    seed = 1234,
                                    verbose = FALSE)
classifier

```

# Prediction

## Initial test

```{r}

# apply on the training data
# To have the classes in output in specific order, we can use classes argument
results_train <- predict_one_vs_rest_TSP(classifier = classifier,
                                         Data = train_object,
                                         tolerate_missed_genes = TRUE,
                                         weighted_votes = TRUE,
                                         classes =  unique_classes,
                                         verbose = TRUE)

# apply on the testing data
results_test <- predict_one_vs_rest_TSP(classifier = classifier,
                                        Data = test,
                                        tolerate_missed_genes = TRUE,
                                        weighted_votes = TRUE,
                                        classes= unique_classes,
                                        verbose = TRUE)
# get a look over the scores in the testing data
knitr::kable(head(results_test))

```

## Accuracy

```{r}

# Confusion Matrix and Statistics on training data
caret::confusionMatrix(data = factor(results_train$max_score, 
                                     levels = unique_classes),
                       reference = factor(train_object$data$Labels, 
                                          levels = unique_classes),
                       mode="everything")
```

## Confusion matrix

```{r}

# Extract sample names from the columns of the test object
# Step 1: Extract sample names from the columns of the test object
test_samples <- colnames(test)

# Step 2: Extract the labels for these samples from tpms_df
test_labels <- tpms_df[test_samples, classifier_label]

# Step 3: Convert test_labels to a factor with the correct levels
test_labels <- as.factor(test_labels)

# Step 4: Ensure predicted_labels has the same levels as test_labels
common_levels <- union(levels(test_labels), unique(train_object$Labels))

# test_labels <- factor(test_labels, levels = common_levels)
predicted_labels <- factor(results_test$max_score, levels = common_levels)

# Step 5: Compute the confusion matrix
confusion_matrix <- caret::confusionMatrix(data = predicted_labels,
                                           reference = test_labels,
                                           mode = "everything")

# Print the confusion matrix
print(confusion_matrix)


```

# Visusalisation

## Train data

```{r}

# plot for the rules and scores in the training data
plot_binary_TSP(Data = train_object, # we are using the data object here
                classifier = classifier, 
                prediction = results_train, 
                classes = unique_classes,
                #margin = c(0,5,0,10),
                title = "Training data")

```

## Test data

```{r}

# plot for the rules and scores in the testing data
plot_binary_TSP(Data = test, # ExpressionSet
                ref=test_labels,
                classifier = classifier, 
                prediction = results_test, 
                classes = unique_classes,
                title = "Testing data"#, 
                #margin = c(0,5,0,10)
                )

```
